{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection with Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('news.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "8476                        You Can Smell Hillary’s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875     The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                    text label  \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "3608   U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "875    It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6335 entries, 8476 to 4330\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   6335 non-null   object\n",
      " 1   text    6335 non-null   object\n",
      " 2   label   6335 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 198.0+ KB\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging title and text into one text\n",
    "news['text'] = news['title']+' '+news['text']\n",
    "del news['title']\n",
    "\n",
    "# label conversion\n",
    "news['label'] = news['label'].map({'REAL': 0,'FAKE': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "8476   You Can Smell Hillary’s Fear Daniel Greenfield...      1\n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...      1\n",
       "3608   Kerry to go to Paris in gesture of sympathy U....      0\n",
       "10142  Bernie supporters on Twitter erupt in anger ag...      1\n",
       "875    The Battle of New York: Why This Primary Matte...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rakibur\n",
      "[nltk_data]     Rahman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "\n",
    "def text_preprocess(text):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns cleaned text in as string\n",
    "    \"\"\"\n",
    "    # removing punctuation\n",
    "    no_punc = [char for char in text if char not in string.punctuation]\n",
    "\n",
    "    # rejoining the characters to form the string\n",
    "    no_punc = ''.join(no_punc)\n",
    "    \n",
    "    # stemming and removing stopwords\n",
    "    clean = [word for word in no_punc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # rejoining characters to form string\n",
    "    clean = ' '.join(clean)\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1598.8 sec\n"
     ]
    }
   ],
   "source": [
    "# text pre-processing is being executed \n",
    "import time\n",
    "t1 = time.time()\n",
    "news['text'] = news['text'].apply(text_preprocess)\n",
    "t2 = time.time()\n",
    "print('Time taken: {:.1f} sec'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test splitting of data\n",
    "# or only train data if test data is unseen\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(news['text'], news['label'],test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing classifiers\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = {'Logistic Regression': LogisticRegression(),\n",
    "       'Passive-Aggressive': PassiveAggressiveClassifier(),\n",
    "       'K Neighbors': KNeighborsClassifier(), \n",
    "       'Support Vector': SVC(), \n",
    "       'Multinomial NB': MultinomialNB(),\n",
    "       'Decision Tree': DecisionTreeClassifier(), \n",
    "       'Random Forest': RandomForestClassifier(), \n",
    "       'XG Boost': XGBClassifier(use_label_encoder=False, eval_metric='auc')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "def cross_val_report(clf_,X_,y_,cv_):\n",
    "    '''This function gives cross-validated training accuracy for given classifier'''\n",
    "    ti = time.time()\n",
    "    pipeline = Pipeline([('bow',CountVectorizer()), ('tfidf',TfidfTransformer()), ('clf',clf_)])\n",
    "    acc_list = cross_val_score(pipeline, X_train, y_train, cv=cv_, scoring='accuracy')\n",
    "    mean_ = round(100*acc_list.mean(),1)\n",
    "    err_ = round(100*np.sqrt(acc_list.std()/(cv_-1)),1)\n",
    "    accuracy_ = str(mean_)+' $\\pm$ '+str(err_)\n",
    "    \n",
    "    tf = time.time()\n",
    "    time_ = round(tf-ti,1)\n",
    "    \n",
    "    return accuracy_, time_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression took 29.2 sec\n",
      "Passive-Aggressive took 23.7 sec\n",
      "K Neighbors took 24.9 sec\n",
      "Support Vector took 428.4 sec\n",
      "Multinomial NB took 23.0 sec\n",
      "Decision Tree took 67.3 sec\n",
      "Random Forest took 73.1 sec\n",
      "XG Boost took 302.7 sec\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "time_taken = []\n",
    "\n",
    "for i in range(len(clf)):\n",
    "    accuracy_, time_ = \\\n",
    "    cross_val_report(list(clf.values())[i],X_train,y_train,10)\n",
    "    accuracy.append(accuracy_)\n",
    "    time_taken.append(time_)\n",
    "    print(list(clf.keys())[i]+' took {} sec'.format(time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for cross validation\n",
    "\n",
    "cross_val_data = {'Train Accuracy (%)': accuracy, 'Time (sec)': time_taken}\n",
    "df1 = pd.DataFrame(index=clf.keys(), data=cross_val_data, columns=cross_val_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy (%)</th>\n",
       "      <th>Time (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>91.5 $\\pm$ 3.8</td>\n",
       "      <td>29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive-Aggressive</th>\n",
       "      <td>93.6 $\\pm$ 3.0</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Neighbors</th>\n",
       "      <td>84.7 $\\pm$ 3.6</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector</th>\n",
       "      <td>93.1 $\\pm$ 3.0</td>\n",
       "      <td>428.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>83.2 $\\pm$ 3.6</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>81.1 $\\pm$ 4.1</td>\n",
       "      <td>67.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>91.1 $\\pm$ 3.1</td>\n",
       "      <td>73.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG Boost</th>\n",
       "      <td>92.6 $\\pm$ 3.7</td>\n",
       "      <td>302.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Train Accuracy (%)  Time (sec)\n",
       "Logistic Regression     91.5 $\\pm$ 3.8        29.2\n",
       "Passive-Aggressive      93.6 $\\pm$ 3.0        23.7\n",
       "K Neighbors             84.7 $\\pm$ 3.6        24.9\n",
       "Support Vector          93.1 $\\pm$ 3.0       428.4\n",
       "Multinomial NB          83.2 $\\pm$ 3.6        23.0\n",
       "Decision Tree           81.1 $\\pm$ 4.1        67.3\n",
       "Random Forest           91.1 $\\pm$ 3.1        73.1\n",
       "XG Boost                92.6 $\\pm$ 3.7       302.7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of tunable hyperparameters of various classifiers\n",
    "\n",
    "from scipy.stats import expon\n",
    "\n",
    "hp = {'K Neighbors': dict(n_neighbors = list(range(1,31)),\n",
    "                          metric = ['euclidean', 'manhattan', 'minkowski'], \n",
    "                          weights = ['uniform', 'distance']),\n",
    "      'Passive-Aggressive': dict(C = 10.**np.arange(-3, 3),\n",
    "                                 max_iter = list(range(1_000,10_100,100))),\n",
    "      'Logistic Regression': dict(C = 10.**np.arange(-3, 3),\n",
    "                                  penalty = ['l1', 'l2', 'elasticnet']),\n",
    "      'Decision Tree': dict(criterion = ['gini', 'entropy'],\n",
    "                            min_samples_leaf = list(range(1,10)),\n",
    "                            max_depth = list(range(2,14,2))),\n",
    "      'Support Vector': dict(C = expon(scale=100),      # param distribution for SVC \n",
    "                             gamma = expon(scale=.1)),\n",
    "      'Random Forest': dict(n_estimators = [10,50,100,500,1000],\n",
    "                            max_features = ['auto', 'sqrt', 'log2']),\n",
    "      'XG Boost': dict(learning_rate = 0.1*np.arange(1,11), # default = 0.3\n",
    "                       max_depth = list(range(2,31,2)),  # default = 6\n",
    "                       min_child_weight = 10.**np.arange(-2,3), # default = 1\n",
    "                       min_split_loss = 0.1**np.arange(0,5), # default = 0\n",
    "                       colsample_bytree = 0.1*np.arange(1,11))} # default = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary for best estimators\n",
    "\n",
    "best_values = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def best_estimator(clf_name,X_,y_,cv_,rs_=False,n_iter=None):\n",
    "    '''This function finds best estimator for a given classifier'''\n",
    "    ti = time.time()\n",
    "    if rs_:\n",
    "        grid = RandomizedSearchCV(clf[clf_name], param_distributions=hp[clf_name], \n",
    "                                  n_iter=n_iter, scoring='accuracy', n_jobs=-1, cv=cv_)\n",
    "    else:\n",
    "        grid = GridSearchCV(clf[clf_name], param_grid=hp[clf_name], \n",
    "                        scoring='accuracy', n_jobs=-1, cv=cv_)\n",
    "    pipeline = Pipeline([('bow',CountVectorizer()),('tfidf',TfidfTransformer()), \n",
    "                     ('grid',grid)])\n",
    "    pipeline.fit(X_,y_)\n",
    "    \n",
    "    best_score = round(100*grid.best_score_,1)\n",
    "    best_pipeline = Pipeline([('bow',CountVectorizer()),('tfidf',TfidfTransformer()), \n",
    "                           ('best_est',grid.best_estimator_)])\n",
    "    \n",
    "    tf = time.time()\n",
    "    time_ = round(tf-ti,1)\n",
    "    \n",
    "    best_values[clf_name] = [best_score, best_pipeline, time_]\n",
    "    \n",
    "    print(clf_name+' took '+str(time_)+' sec; best train accuracy: '+str(best_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression took 21.0 sec; best train accuracy: 93.7%\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for Logistic Regression\n",
    "\n",
    "best_estimator('Logistic Regression',X_train,y_train,cv_=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passive-Aggressive took 610.5 sec; best train accuracy: 94.1%\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for Passive-Aggressive\n",
    "\n",
    "best_estimator('Passive-Aggressive',X_train,y_train,cv_=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Neighbors took 1287.2 sec; best train accuracy: 86.1%\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for K Neighbors\n",
    "\n",
    "best_estimator('K Neighbors',X_train,y_train,cv_=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector took 1106.1 sec; best train accuracy: 93.9%\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for Support vector\n",
    "\n",
    "best_estimator('Support Vector',X_train,y_train,cv_=10,rs_=True,n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree took 637.5 sec; best train accuracy: 82.2%\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for Decision Tree\n",
    "\n",
    "best_estimator('Decision Tree',X_train,y_train,cv_=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest took 1322.9 sec; best train accuracy: 91.5%\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for Random Forest\n",
    "\n",
    "best_estimator('Random Forest',X_train,y_train,cv_=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost took 2556.9 sec; best train accuracy: 92.7%\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for XG Boost\n",
    "\n",
    "best_estimator('XG Boost',X_train,y_train,cv_=10,rs_=True,n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for best training scores\n",
    "\n",
    "def best_list(index):\n",
    "    return [list(best_values.values())[i][index] for i in range(len(best_values))]\n",
    "        \n",
    "best_new = {'Best Score (%)': best_list(0), 'Search Time (sec)': best_list(2)}\n",
    "df2 = pd.DataFrame(index=best_values.keys(), data=best_new, columns=best_new.keys())\n",
    "\n",
    "# inclusion of default performance\n",
    "df_best = pd.concat([df2,df1['Train Accuracy (%)'].apply(lambda i: float(i[0:4]))], axis=1)\n",
    "df_best.rename(columns={'Train Accuracy (%)':'Default Accuracy (%)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Score (%)</th>\n",
       "      <th>Search Time (sec)</th>\n",
       "      <th>Default Accuracy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>93.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>91.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive-Aggressive</th>\n",
       "      <td>94.1</td>\n",
       "      <td>610.5</td>\n",
       "      <td>93.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Neighbors</th>\n",
       "      <td>86.1</td>\n",
       "      <td>1287.2</td>\n",
       "      <td>84.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector</th>\n",
       "      <td>93.9</td>\n",
       "      <td>1106.1</td>\n",
       "      <td>93.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>82.2</td>\n",
       "      <td>637.5</td>\n",
       "      <td>81.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>91.5</td>\n",
       "      <td>1322.9</td>\n",
       "      <td>91.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG Boost</th>\n",
       "      <td>92.7</td>\n",
       "      <td>2556.9</td>\n",
       "      <td>92.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Best Score (%)  Search Time (sec)  Default Accuracy (%)\n",
       "Logistic Regression            93.7               21.0                  91.5\n",
       "Passive-Aggressive             94.1              610.5                  93.6\n",
       "K Neighbors                    86.1             1287.2                  84.7\n",
       "Support Vector                 93.9             1106.1                  93.1\n",
       "Decision Tree                  82.2              637.5                  81.1\n",
       "Random Forest                  91.5             1322.9                  91.1\n",
       "XG Boost                       92.7             2556.9                  92.6\n",
       "Multinomial NB                  NaN                NaN                  83.2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "\n",
    "def test_result(clf_name,X_,y_,X_new,y_new):\n",
    "    '''This function evaluates various performance metrics on test data'''\n",
    "    if clf_name in best_values.keys():\n",
    "        best_pipeline = best_values[clf_name][1]\n",
    "    elif clf_name in clf.keys():\n",
    "        best_pipeline =\\\n",
    "        Pipeline([('bow',CountVectorizer()),('tfidf',TfidfTransformer()),('clf',clf[clf_name])])\n",
    "    \n",
    "    best_pipeline.fit(X_,y_)\n",
    "    y_pred = best_pipeline.predict(X_new)\n",
    "    \n",
    "    accuracy = round(accuracy_score(y_new,y_pred),3)\n",
    "    precision = round(precision_score(y_new,y_pred),3)\n",
    "    recall = round(recall_score(y_new,y_pred),3)\n",
    "    f1 = round(f1_score(y_new,y_pred),3)\n",
    "    \n",
    "    return accuracy, precision,recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of performance metrics\n",
    "\n",
    "metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'f1 Score': []}\n",
    "for estimator in df_best.index:\n",
    "    accuracy,precision,recall,f1 = test_result(estimator,X_train,y_train,X_test,y_test)\n",
    "    metrics['Accuracy'].append(accuracy)\n",
    "    metrics['Precision'].append(precision)\n",
    "    metrics['Recall'].append(recall)\n",
    "    metrics['f1 Score'].append(f1)\n",
    "\n",
    "df_result = pd.DataFrame(index=df_best.index, data=metrics, columns=metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive-Aggressive</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Neighbors</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG Boost</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision  Recall  f1 Score\n",
       "Logistic Regression     0.940      0.914   0.967     0.940\n",
       "Passive-Aggressive      0.942      0.926   0.956     0.941\n",
       "K Neighbors             0.867      0.926   0.790     0.852\n",
       "Support Vector          0.935      0.910   0.961     0.935\n",
       "Decision Tree           0.802      0.767   0.850     0.806\n",
       "Random Forest           0.914      0.912   0.910     0.911\n",
       "XG Boost                0.923      0.917   0.923     0.920\n",
       "Multinomial NB          0.846      0.975   0.700     0.815"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passive Aggressive Classifier is the best performer.\n",
    "Liner Regression is the second best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting classifier of 3 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def voting_(voter_list,vote_type):\n",
    "    '''This function creates a voting classifier of 3 estimators,\n",
    "    which is subsequently trained and tested'''\n",
    "    \n",
    "    # creating voting classifier\n",
    "    estimator_list = []\n",
    "    for clf_name in voter_list:\n",
    "        if clf_name in best_values.keys():\n",
    "            estimator_list.append((clf_name,best_values[clf_name][1]))\n",
    "        else:\n",
    "            pipeline =\\\n",
    "            Pipeline([('bow',CountVectorizer()),('tfidf',TfidfTransformer()),\n",
    "                      ('clf',clf[clf_name])])\n",
    "            estimator_list.append((clf_name,pipeline))\n",
    "    voting_clf = VotingClassifier(estimators=estimator_list,voting=vote_type)\n",
    "    \n",
    "    # training and testing\n",
    "    voting_clf.fit(X_train,y_train)\n",
    "    y_pred = voting_clf.predict(X_test)\n",
    "    \n",
    "    # evaluation of metrics\n",
    "    accuracy = round(accuracy_score(y_test,y_pred),3)\n",
    "    precision = round(precision_score(y_test,y_pred),3)\n",
    "    recall = round(recall_score(y_test,y_pred),3)\n",
    "    f1 = round(f1_score(y_test,y_pred),3)\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the bottom 3 performers: 'K Neighbors', 'Decision Tree', 'Multinomial NB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "voter_list = ['K Neighbors', 'Decision Tree', 'Multinomial NB']\n",
    "\n",
    "# create a dataframe of performance metrics\n",
    "\n",
    "voting_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'f1 Score': []}\n",
    "for vote_type in ['hard','soft']:\n",
    "        accuracy, precision, recall, f1 = voting_(voter_list,vote_type)\n",
    "        voting_metrics['Accuracy'].append(accuracy)\n",
    "        voting_metrics['Precision'].append(precision)\n",
    "        voting_metrics['Recall'].append(recall)\n",
    "        voting_metrics['f1 Score'].append(f1)\n",
    "\n",
    "df_voting = pd.DataFrame(index=['Hard Voting','Soft Voting'],\n",
    "                         data=voting_metrics, columns=voting_metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hard Voting</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soft Voting</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Precision  Recall  f1 Score\n",
       "Hard Voting     0.897      0.964   0.818     0.885\n",
       "Soft Voting     0.894      0.936   0.839     0.885"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting classifier has much more improved predictions than individual voters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
